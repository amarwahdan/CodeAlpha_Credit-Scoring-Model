# -*- coding: utf-8 -*-
"""Credit Scoring Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1j_Vrkg-xGkmbYjkg9aPi4tKJz6vI3yQD

# Credit Scoring Model

# Introduction

This project aims to develop a machine learning model to predict an individual's creditworthiness using personal and financial attributes. By analyzing key factors such as income, credit history, loan amount, and debt ratio, the model helps assess the risk of default and supports more informed lending decisions.
The model classification algorithms including XGBoost, with a focus on handling class imbalance, feature engineering, and model interpretability. The dataset used in this project is publicly available and contains thousands of real-world loan applications with labels indicating loan status approved or denied.

Data Source: https://www.kaggle.com/datasets/taweilo/loan-approval-classification-data/data

**Amar Ahmed**

**Data Scientist** | **Machine Learning Engineer** | **Computer Vision Researcher**
"""

!pip install ydata_profiling

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from ydata_profiling import ProfileReport

# Load Data
Data = pd.read_csv('/content/loan_data.csv')
Data.head()

# Data Overview
display("Data size:", Data.shape)
print('--------------------------------------------')
display("\n columns:", Data.columns.tolist())
print('--------------------------------------------')
display("\n Data type:", Data.dtypes)
print('--------------------------------------------')

Data.info()

Data.describe()

Data.describe(include='object')

Data.isnull().sum()

Data.duplicated().sum()

Data['loan_status'].value_counts() # problem (imbalans) -->

Data['person_gender'].value_counts()

Data['person_education'].value_counts()

Data['person_home_ownership'].value_counts()

Data['loan_intent'].value_counts()

"""# **EDA**

# **what Age Mean**
"""

Data['person_age'].mean() # 27 Years

"""# **How old is the person who gets the highest salary?**"""

Data[Data['person_income'] == Data['person_income'].max()]['person_age']

"""# **Highest debt ratio**"""

Data[Data['loan_percent_income'] == Data['loan_percent_income'].max()]

figsize = (12, 1.2 * len(Data['person_education'].unique()))
plt.figure(figsize=figsize)
sns.violinplot(Data, x='person_age', y='person_education', inner='box', palette='Dark2')
sns.despine(top=True, right=True, bottom=True, left=True)

Data['person_emp_exp'].plot(kind='line', figsize=(8, 4), title='person_emp_exp', color='red')
plt.gca().spines[['top', 'right']].set_visible(False)

Data.groupby('loan_intent').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))
plt.gca().spines[['top', 'right',]].set_visible(False)

plt.subplots(figsize=(8, 8))
df_2dhist = pd.DataFrame({
    x_label: grp['loan_intent'].value_counts()
    for x_label, grp in Data.groupby('person_home_ownership')
})
sns.heatmap(df_2dhist, cmap='viridis')
plt.xlabel('person_home_ownership')
_ = plt.ylabel('loan_intent')

"""# ***FULL REPORT***"""

# ProfileReport(Data)

"""# **Data Cleaning & Preprocessing**"""

def Data_preprocessing(CreditScoring_Data):
    # Label Encoding
    label_cols = ["person_gender", "person_education", "person_home_ownership",
                  "loan_intent", "previous_loan_defaults_on_file"]

    for col in label_cols:
        le = LabelEncoder()
        CreditScoring_Data[col] = le.fit_transform(CreditScoring_Data[col])

    for col in CreditScoring_Data.columns:
        if CreditScoring_Data[col].dtype == 'object':
            CreditScoring_Data[col] = pd.to_numeric(CreditScoring_Data[col], errors='coerce')
        CreditScoring_Data.dropna(inplace=True)
    return CreditScoring_Data

def Remove_Outliers(CreditScoring_Data):
    numeric_cols = CreditScoring_Data.select_dtypes(include='number').columns.drop('loan_status')
    # Remove outliers using the IQR method
    for col in numeric_cols:
        Q1 = CreditScoring_Data[col].quantile(0.25) # 25% Data
        Q3 = CreditScoring_Data[col].quantile(0.75) # 75% Data
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        CreditScoring_Data = CreditScoring_Data[(CreditScoring_Data[col] >= lower_bound) & (CreditScoring_Data[col] <= upper_bound)]
    return CreditScoring_Data

"""# **Apply the cleaning functions**"""

Data_Cleaning = Data_preprocessing(Data)
Data_Cleaning = Remove_Outliers(Data_Cleaning)
Data_Cleaning.drop_duplicates(inplace=True)

Data_Cleaning

Data.shape, Data_Cleaning.shape

Data_Cleaning.describe()

# HistPlot
for col in Data_Cleaning.columns:
    if Data_Cleaning[col].dtype == 'int64' or Data_Cleaning[col].dtype == 'float64':
        sns.histplot(Data_Cleaning[col], kde=True)

# ploting
for col in Data_Cleaning.columns:
    if Data_Cleaning[col].dtype == 'int64' or Data_Cleaning[col].dtype == 'float64':
        plt.figure(figsize=(10, 6))
        sns.boxplot(Data_Cleaning[col])
        plt.title(f'Box Plot of {col}')
        plt.show()

# corrletion
plt.figure(figsize=(10, 6))
sns.heatmap(Data_Cleaning.corr(), annot=True, cmap='coolwarm')
plt.title('Correlation Heatmap')
plt.show()

sns.pairplot(Data_Cleaning)
plt.suptitle('Pairplot of Data', y=1.02)
plt.show()

"""# **Spliting Dataset**"""

from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE

# SPLITING
x = Data_Cleaning.drop('loan_status', axis=1)
y = Data_Cleaning['loan_status']
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)
# SMOTE
smote = SMOTE(random_state=42) # Solve the imbalance problem
x_train_resampled, y_train_resampled = smote.fit_resample(x_train, y_train)
# SCALE
scaler = StandardScaler()
x_train = scaler.fit_transform(x_train_resampled)
x_test = scaler.transform(x_test)

"""# **Model**"""

from xgboost import XGBClassifier

xgb = XGBClassifier()
xgb.fit(x_train, y_train_resampled)
xgb.score(x_test, y_test)

y_pred = xgb.predict(x_test)
y_test[:10], y_pred[:10]

from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, accuracy_score

class_report = classification_report(y_test, y_pred)
print(class_report)

CM = confusion_matrix(y_test, y_pred)
sns.heatmap(CM, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.show()

roc_auc_score(y_test, y_pred)

"""# **Building Application For Gradio**"""

!pip install gradio

import gradio as gr
import numpy as np
import joblib

def predict_loan_status(person_age, person_gender, person_education, person_income, person_emp_exp,
                        person_home_ownership, loan_amnt, loan_intent, loan_int_rate, loan_percent_income,
                        cb_person_cred_hist_length, credit_score, previous_loan_defaults_on_file):

    # Create a NumPy array from the input values
    input_data = np.array([[person_age, person_gender, person_education, person_income, person_emp_exp,
                            person_home_ownership, loan_amnt, loan_intent, loan_int_rate, loan_percent_income,
                            cb_person_cred_hist_length, credit_score, previous_loan_defaults_on_file]])

    # Scale the input data using the same scaler used for training
    input_data_scaled = scaler.transform(input_data)

    # Make the prediction
    prediction = xgb.predict(input_data_scaled)

    # Return the prediction as a human-readable string
    if prediction[0] == 1:
        return "Loan Status: Default"
    else:
        return "Loan Status: Non-Default"

# Create Gradio interface
interface = gr.Interface(
    fn=predict_loan_status,
    inputs=[
        gr.Number(label="Person Age"),
        gr.Radio(["Female", "Male"], label="Person Gender"),
        gr.Dropdown(["Bachelor", "Associate", "High School", "Master", "Doctorate"], label="Person Education"),
        gr.Number(label="Person Income"),
        gr.Number(label="Person Employment Experience"),
        gr.Radio(["RENT", "MORTGAGE", "OWN", "OTHER"], label="Person Home Ownership"),
        gr.Number(label="Loan Amount"),
        gr.Dropdown(["EDUCATION", "MEDICAL", "VENTURE", "PERSONAL", "DEBTCONSOLIDATION", "HOMEIMPROVEMENT"], label="Loan Intent"),
        gr.Number(label="Loan Interest Rate"),
        gr.Number(label="Loan Percent Income"),
        gr.Number(label="Credit History Length"),
        gr.Number(label="Credit Score"),
        gr.Radio(["Yes", "No"], label="Previous Loan Defaults on File")
    ],
    outputs=gr.Textbox(label="Prediction")
)

# Launch the interface
interface.launch(inline=True)

"""# *Thank you for checking out this notebook! ❤️❤️*"""